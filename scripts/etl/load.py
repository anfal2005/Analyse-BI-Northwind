import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.engine import URL

# --------------------------------------------------------
# SQL CONNECTION
# --------------------------------------------------------
import urllib
connection_string = (
    "DRIVER={ODBC Driver 17 for SQL Server};"
    "SERVER=DESKTOP-VT8AV69\\SQLEXPRESS;"
    "DATABASE=DataWarehouse;"
    "Trusted_Connection=yes;"
)

connection_string = urllib.parse.quote_plus(connection_string)

engine = create_engine(f"mssql+pyodbc:///?odbc_connect={connection_string}")


def load_excel_to_sql(path, table_name):
    print(f"Loading file: {path}")

    df = pd.read_excel(path)
    # Insert into SQL (ID auto generated by SQL)
    df.to_sql(
        table_name,
        engine,
        if_exists="append",
        index=False
    )

    print(f"Imported successfully into '{table_name}' table!\n")


# --------------------------------------------------------
# RUN LOADING
# --------------------------------------------------------
load_excel_to_sql(
    r"..\cleaned files\dbo.client.xlsx",
    "client"
)

load_excel_to_sql(
    r"..\cleaned files\dbo.employee.xlsx",
    "employee"
)





# --------------------------------------------------------
# LOAD FACT TABLE
# --------------------------------------------------------
df_fact = pd.read_excel(
    r"..\cleaned files\dbo.faitcommande2.xlsx"
)

# --------------------------------------------------------
# LOAD DIMENSIONS FROM SQL TO MAP FOREIGN KEYS
# --------------------------------------------------------
df_clients = pd.read_sql("SELECT id_client, customerid FROM client", engine)
df_employees = pd.read_sql("SELECT id_employee, employeeid FROM employee", engine)
df_dates = pd.read_sql("SELECT id_date FROM temps ORDER BY startdate", engine)

# --------------------------------------------------------
# ASSIGN DATES TO ORDERS
# --------------------------------------------------------
if len(df_fact) > len(df_dates):
    raise ValueError("Not enough dates in temps table for all orders!")

df_fact['date_id'] = df_dates['id_date'].iloc[:len(df_fact)].values

# --------------------------------------------------------
# MAP CLIENT AND EMPLOYEE IDS TO FOREIGN KEYS
# --------------------------------------------------------
df_fact = df_fact.merge(
    df_clients, left_on='customer_id', right_on='customerid', how='left'
)
df_fact = df_fact.merge(
    df_employees, left_on='employee_id', right_on='employeeid', how='left'
)

# --------------------------------------------------------
# KEEP ONLY COLUMNS NEEDED IN FACT TABLE
# --------------------------------------------------------
df_sql = df_fact[
    ['id_client', 'id_employee', 'date_id', 'order_id', 'ship_address', 'ship_country', 'order_status']
]
df_sql.rename(columns={
    'id_client': 'customer_id',
    'id_employee': 'employee_id'
}, inplace=True)
# --------------------------------------------------------
# INSERT INTO SQL FACT TABLE
# --------------------------------------------------------
df_sql.to_sql("faitcommande", engine, if_exists="append", index=False)
print("Fact table imported successfully!")